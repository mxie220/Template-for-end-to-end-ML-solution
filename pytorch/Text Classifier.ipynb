{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.3\n"
     ]
    }
   ],
   "source": [
    "# First we want to check what version of python we are running here: \n",
    "import sys\n",
    "print(\"Python version: \" + str(sys.version_info.major) + \".\" + str(sys.version_info.minor) + \".\" + str(sys.version_info.micro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mixie\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: future in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: torchtext in c:\\users\\mixie\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from torchtext) (1.18.5)\n",
      "Requirement already satisfied: requests in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from torchtext) (2.24.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from torchtext) (0.1.91)\n",
      "Requirement already satisfied: six in c:\\users\\mixie\\appdata\\roaming\\python\\python38\\site-packages (from torchtext) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from torchtext) (4.47.0)\n",
      "Requirement already satisfied: torch in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from torchtext) (1.6.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from requests->torchtext) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from requests->torchtext) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: future in c:\\users\\mixie\\anaconda3\\lib\\site-packages (from torch->torchtext) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported TorchText module from PyTorch.\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "print(\"Successfully imported TorchText module from PyTorch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported some datasets from TorchText.\n"
     ]
    }
   ],
   "source": [
    "# Import some datasets from TorchText\n",
    "from torchtext.datasets import text_classification\n",
    "print(\"Successfully imported some datasets from TorchText.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\ag_news_csv.tar.gz: 11.8MB [00:02, 5.04MB/s]\n",
      "120000lines [00:31, 3816.44lines/s]\n",
      "120000lines [01:05, 1831.94lines/s]\n",
      "7600lines [00:04, 1680.21lines/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating a folder called 'data'\n",
    "import os\n",
    "if not os.path.isdir('./.data'):\n",
    "    os.mkdir('./.data')\n",
    "    \n",
    "# Specifying how to break up the dataset into n-words \n",
    "NGRAMS = 2\n",
    "\n",
    "# Load the training dataset and testing dataset\n",
    "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
    "    root='./.data', ngrams=NGRAMS, vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the neural network package from PyTorch \n",
    "import torch.nn as nn\n",
    "\n",
    "# We also want to the functional module which contains all the functions in the torch.nn library.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Creating a class called TextSentiment that takes in the neural network module from Pytorch.\n",
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        # The EmbeddingBag module finds the sum or the mean of all the embeddings.\n",
    "        # An embedding allows you to map low-dimensional real vectors that can represent each words to other words that are similar. \n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        # This does a Linear Transformation which allows the model to learn the weights between the embeddings and maps it to an output class\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        # intialization range set at 0.5\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    # This is the forward propagation which essentially feeds input data into each layer of the model \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size is:  1308844\n",
      "The number of classes is:  4\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUM_CLASS = len(train_dataset.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUM_CLASS)\n",
    "\n",
    "print(\"The vocabulary size is: \", VOCAB_SIZE)\n",
    "print(\"The number of classes is: \", NUM_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    # A tensor is used to represent n-Dimensions of features. It looks like a matrix but it's not a matrix, a matrix is simply used to visualize a tensor. \n",
    "    # The first part of the entry is the class label (e.g. what type of news article).\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    # The second part of the entry is the text. \n",
    "    text = [entry[1] for entry in batch]\n",
    "    # These are the offset values in storage which indicates where the tensors start from.\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    \n",
    "    # torch.Tensor.cumsum returns a cumulative sum of all the elements in the dimension.\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    \n",
    "    # torch.cat concatenates whatever you give it together. \n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Dataloder is used to load the data and then send it to the model for traning and validation \n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    #  a function dataloder is called here with the parameters to be passed for thr validation of our model\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    # Adjust the learning rate  fir the number of epoches taken\n",
    "    scheduler.step()\n",
    "    \n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
    "    \n",
    "#testing the model\n",
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the data with the test dataset..\n",
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(test_dataset)\n",
    "#finally the locc and the accuracy are calculated\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model on some random data \n",
    "import re\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "#different labels taken into consideration\n",
    "ag_news_label = {1 : \"World\",\n",
    "                 2 : \"Sports\",\n",
    "                 3 : \"Business\",\n",
    "                 4 : \"Sci/Tec\"}\n",
    "\n",
    "#Use of the trained model and the bgrams for the classification\n",
    "def predict(text, model, vocab, ngrams):\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor([vocab[token]\n",
    "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "#example input text taken\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "vocab = train_dataset.get_vocab()\n",
    "model = model.to(\"cpu\")\n",
    "#final classification of the taken input text\n",
    "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}